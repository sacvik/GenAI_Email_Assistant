{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c84b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a352de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = \"Sachin\"\n",
    "\n",
    "# Your company domain (for filtering internal emails)\n",
    "internal_domain = \"@spglobal.com\"\n",
    "\n",
    "# Connect to Outlook\n",
    "outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "\n",
    "# Select Inbox (can be modified if you're using a subfolder)\n",
    "inbox = outlook.GetDefaultFolder(6)  # 6 refers to inbox\n",
    "messages = inbox.Items\n",
    "messages.Sort(\"[ReceivedTime]\", True)  # sort by latest first\n",
    "# cond\n",
    "# messages = messages.Restrict(f\"[ReceivedTime] >= '{yesterday}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9487831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_to_ignore = [\n",
    "    'Kapow.Sourcing@spglobal.com'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f92eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"@spglobal.com\"\n",
    "\n",
    "data = []\n",
    "for message in messages:\n",
    "    try:\n",
    "\n",
    "        if message.SenderEmailType == \"EX\":\n",
    "            # For Exchange senders (internal colleagues)\n",
    "            smtp_address = message.Sender.GetExchangeUser().PrimarySmtpAddress\n",
    "        else:\n",
    "            # For external SMTP senders\n",
    "            smtp_address = message.SenderEmailAddress\n",
    "\n",
    "        if (smtp_address is not None) & (smtp_address.endswith(pattern)):\n",
    "            if smtp_address not in emails_to_ignore:\n",
    "                subject = message.Subject\n",
    "                body = message.Body\n",
    "                date = message.ReceivedTime.strftime(\"%Y-%m-%d\")\n",
    "                if (date < '2025-06-28'):\n",
    "                    break\n",
    "                mentioned = \"yes\" if re.search(rf\"\\b{your_name}\\b\", body, re.IGNORECASE) else \"no\"\n",
    "                data.append([date, subject, body, smtp_address, mentioned])\n",
    "                \n",
    "    except Exception as e:\n",
    "        # Skip if something fails (e.g., a meeting invite without a sender email)\n",
    "        continue\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ad0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Date\", \"subject\", \"body\", \"sender\", \"Mentioned\"]).sort_values(by=\"sender\", ascending=False)\n",
    "df.to_csv('email.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb8055a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p = df[df.Mentioned == 'yes'][['sender', 'subject', 'body']]\n",
    "df_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357134b1",
   "metadata": {},
   "source": [
    "## Deploying LLM extraction and summarization tool using Ollama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4baf50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q langchain langgraph openai pandas Langchain-community langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ef64ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachin.verma\\AppData\\Local\\Temp\\ipykernel_30180\\2470696828.py:7: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"mistral\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "## \n",
    "llm = ChatOllama(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\n",
    "    [HumanMessage(content= \"\"\"Hi\"\"\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0e5109a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Hello! How can I help you today?\\n\\nAsk me anything related to programming, data science, machine learning, or artificial intelligence, and I'll do my best to assist you. If you have any specific problems or projects you're working on, feel free to share them with me. I'm here to learn and grow alongside you!\\n\\nIf you have any other topics you'd like to discuss, just let me know. I'm always excited to engage in interesting conversations and help others along their learning journey. What can I assist you with today?\", additional_kwargs={}, response_metadata={'model': 'mistral', 'created_at': '2025-07-01T09:34:50.5088602Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 109837304200, 'load_duration': 18104900, 'prompt_eval_count': 5, 'prompt_eval_duration': 50428572500, 'eval_count': 120, 'eval_duration': 59389565700}, id='run--af38b1b6-eccc-4a69-b724-f343f9b61b89-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71c00f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import Runnable\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# 1. Preprocess\n",
    "def preprocess_email(state):\n",
    "    email = state[\"email\"]\n",
    "    full_text = f\"Sender: {email['sender']}\\nSubject: {email['subject']}\\nBody: {email['body']}\"\n",
    "    return {\"email_text\": full_text}\n",
    "\n",
    "# 2. Summarize using Ollama\n",
    "def summarize_with_ollama(state):\n",
    "    prompt = f\"\"\"You are an email assistant. Summarize this email and suggest a reply. keep the headings in bold and use markdown format. Dont give any additional information:\\n\\n{state['email_text']}\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"response\": response.content}\n",
    "\n",
    "# 3. Output step\n",
    "def output_summary(state):\n",
    "    display(\"AI Summary & Suggested Reply:\")\n",
    "    display(Markdown(state[\"response\"]))\n",
    "    return state\n",
    "\n",
    "# 4. Define the graph\n",
    "graph = StateGraph(dict)\n",
    "graph.add_node(\"preprocess\", preprocess_email)\n",
    "graph.add_node(\"summarize\", summarize_with_ollama)\n",
    "graph.add_node(\"output\", output_summary)\n",
    "\n",
    "graph.set_entry_point(\"preprocess\")\n",
    "graph.add_edge(\"preprocess\", \"summarize\")\n",
    "graph.add_edge(\"summarize\", \"output\")\n",
    "graph.add_edge(\"output\", END)\n",
    "\n",
    "chain = graph.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f38af1f",
   "metadata": {},
   "source": [
    "## Invoke the Chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ad2fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¢ Processing email...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI Summary & Suggested Reply:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " **Email Summary**\n",
       "\n",
       "The email chain discusses a data extraction issue for the Port Hedland source. Initially, Vismaya reported the problem on May 6th and requested Manoj's team to look into it. On April 21st, Vismaya followed up again, explaining that there were deviations in the data extraction for the latest file of the Port Hedland source. Varsha responded on June 30th, stating that the issue has been resolved and only the correct file will be uploaded to S3 moving forward.\n",
       "\n",
       "**Suggested Reply:**\n",
       "\n",
       "Hi Varsha,\n",
       "\n",
       "Thank you for promptly addressing the data extraction issue for the Port Hedland source. We appreciate your team's quick response and ensure that there are no further issues going forward. If we have any concerns or questions regarding this matter, we will reach out to you immediately.\n",
       "\n",
       "Best Regards,\n",
       "[Your Name]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "ðŸŸ¢ Processing email...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI Summary & Suggested Reply:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " **Email Summary**\n",
       "\n",
       "* Vismaya reported a data extraction issue with the Port Hedland source, where multiple files were uploaded to S3 instead of the expected single file. The files contained old and incorrect date information.\n",
       "* Varsha responded that the issue has been resolved, and only the correct file will be uploaded going forward.\n",
       "\n",
       "**Reply Suggestion**\n",
       "\n",
       "Subject: Re: Resolved - Data extraction issue for the Port Hedland source\n",
       "\n",
       "Hi Vismaya,\n",
       "\n",
       "Thank you for bringing this issue to our attention and for your prompt response. We have ensured that the issue has been rectified, and going forward, only the correct file will be uploaded to S3 as expected.\n",
       "\n",
       "Let us know if you face any further issues related to data extraction from the Port Hedland source.\n",
       "\n",
       "Best Regards,\n",
       "[Your Name]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "ðŸŸ¢ Processing email...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI Summary & Suggested Reply:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " It seems like you've shared a transcript of an email or chat containing meeting details. If you need help with scheduling a meeting, I can certainly guide you on how to do that. Here are the steps:\n",
       "\n",
       "1. Choose a meeting platform such as Microsoft Teams, Zoom, Google Meet, etc., based on your preference and the preferences of the participants.\n",
       "\n",
       "2. Decide on a date and time that works for everyone involved. Consider the time zones if you're scheduling with people in different locations.\n",
       "\n",
       "3. Prepare an invitation containing essential details like the purpose of the meeting, date, time, duration, and a link to join the meeting (if it's online). If it's an in-person meeting, provide the location details.\n",
       "\n",
       "4. Send the invitation via email or any messaging platform that you and your participants use frequently. You can also use calendar invites if everyone uses the same digital calendar.\n",
       "\n",
       "5. Follow up with reminders closer to the meeting date to ensure everyone is aware of the schedule.\n",
       "\n",
       "If you need help creating a meeting invitation, I can certainly guide you on how to do that as well! Let me know if you have any questions or need further assistance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "ðŸŸ¢ Processing email...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI Summary & Suggested Reply:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " It appears that this text contains the transcript of an email or message, which includes a meeting invitation and a request for data extraction. Here's a summary:\n",
       "\n",
       "1. The meeting is about data extraction. The subject line is not provided in this text snippet.\n",
       "2. The meeting ID is 254 064 036 465, with the passcode \"kLckge\". You can join by phone using +1 862-294-2468,,235636981# or find a local number <https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdialin.teams.microsoft.com%2Fa6bff586-987b-4390-a787-748bbde14b6d%3Fid%3D235636981&data=05%7C02%7Csachin.verma%40spglobal.com%7C3a52a4d43ca34b54c29a08ddb867d184%7C8f3e36ea80394b4081a77dc0599e8645%7C1%7C0%7C638869478238869727%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=N1OtFHflMsFp1UXpZ69FEejZ0dt%2FT4nzo%2FD3uLWiTao%3D&reserved=0>.\n",
       "3. The meeting can also be joined on a video conferencing device with the tenant key: 762655058@t.plcm.vc and Video ID: 118 104 348 6.\n",
       "4. Additional information for organizers, such as meeting options and reset dial-in PIN, can be found at the provided links.\n",
       "5. The body of the message does not contain any explicit request or instructions regarding data extraction, but it seems that the purpose of the meeting is to discuss the details of this task."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "ðŸŸ¢ Processing email...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI Summary & Suggested Reply:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " **Summary**\n",
       "\n",
       "* An email from SPGlobalSPAMQuarantine@spglobal.com regarding a new message in the quarantine for Sachin Verma (sachin.verma@spglobal.com) was received.\n",
       "* The email contains links to view and manage the digest, safe/blocked senders list, and account.\n",
       "* One email from events@it-virtual-summits.com titled \"AI Deployment Summit - A Virtual Event - Registration Now!\" is in the quarantine and can be released or allowed/blocked.\n",
       "\n",
       "**Reply Suggestion**\n",
       "\n",
       "Subject: Re: Spam Quarantine Notification: 1 New Message\n",
       "\n",
       "Dear SPGlobalSPAMQuarantine Team,\n",
       "\n",
       "Thank you for notifying me about the new message in my quarantine. I have reviewed the information and will take appropriate action regarding the email from events@it-virtual-summits.com.\n",
       "\n",
       "Best regards,\n",
       "Sachin Verma"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, row in df_p.iterrows():\n",
    "    print(\"ðŸŸ¢ Processing email...\\n\")\n",
    "    state = {\"email\": row.to_dict()}\n",
    "    chain.invoke(state)\n",
    "    print(\"\\n\" + \"+\"*200 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
